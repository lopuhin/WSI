{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['кто', 'вот', 'какой', 'если', 'кажется', 'два', 'впрочем', 'нас', 'вдруг', 'на', 'всех', 'ей', 'тебя', 'себе', 'свой', 'тем', 'между', 'по', 'сказала', 'даже', 'потом', 'тут', 'им', 'сейчас', 'разве', 'до', 'то', 'не', 'с', 'моя', 'мой', 'сегодня', 'опять', 'чтоб', 'из', '|', 'него', 'как', 'говорил', 'об', 'иногда', 'перед', 'ничего', 'эти', 'но', 'сказал', 'их', 'жизнь', 'про', 'и', 'ж', 'раз', 'наконец', 'себя', 'да', 'чуть', 'хорошо', 'бы', 'эту', 'мне', 'в', 'под', 'нибудь', 'чего', 'без', 'были', 'через', 'за', 'более', 'конечно', 'был', 'будет', 'сказать', 'где', 'почти', 'куда', 'сам', 'один', 'тот', 'еще', 'о', 'ни', 'или', 'так', 'мы', 'зачем', 'она', 'нее', 'тогда', 'никогда', 'больше', 'только', 'нельзя', 'он', 'надо', 'вас', 'вы', 'ему', 'всегда', 'здесь']\n",
      "['час', 'время', 'инцидент', 'хватить', 'некоторый', 'легенда', 'говориться', 'золото', 'находиться', 'конец', 'радуга', 'глубина', '22', 'фут', 'почва', 'становиться']\n",
      "['гнить', 'нераскрытый', 'тайна', 'коридор', 'бояться', 'находить', 'черепок', 'глиняный', 'настоящий', 'череп', 'скелет', 'смочь', 'выбираться']\n",
      "['орхидея', 'совершенно', 'очаровывать', 'становиться', 'любимый', 'цветок', 'рекомендовать', 'поддон', 'класть', 'гравий', 'немного', 'камень', 'сверху', 'ставить', 'орхидея']\n",
      "34188\n"
     ]
    }
   ],
   "source": [
    "with open('../context-clustering/stopwords.txt') as f:\n",
    "    stopwords = {line.strip().split()[0] for line in f if line.strip()}\n",
    "print(list(stopwords)[:100])\n",
    "word = 'горшок'\n",
    "stopwords.add(word)\n",
    "with open('../corpora/ad-nouns-contexts-100k/{}.txt'.format(word)) as f:\n",
    "    texts = [[w for w in line.strip().split() if w not in stopwords] for line in f]\n",
    "for text in texts[:3]:\n",
    "    print(text)\n",
    "print(len(texts))\n",
    "#texts = texts[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1)] [(16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(corpus[0], corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34188\n"
     ]
    }
   ],
   "source": [
    "#from gensim.models.ldamulticore import LdaMulticore as LdaModel\n",
    "from gensim.models import LdaModel\n",
    "print(len(corpus))\n",
    "lda = LdaModel(corpus, id2word=dictionary, num_topics=10, passes=3, alpha='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*каша + 0.010*завистливый + 0.008*печь + 0.007*глиняный + 0.005*кровь + 0.005*дно + 0.005*вода + 0.005*суп + 0.005*ложка + 0.005*2.'),\n",
       " (1,\n",
       "  '0.018*бог + 0.015*обжигать + 0.006*русский + 0.006*вершок + 0.004*брат + 0.004*называть + 0.004*корабль + 0.004*продавать + 0.004*первый + 0.003*адмирал'),\n",
       " (2,\n",
       "  '0.007*глиняный + 0.006*государь + 0.006*сосуд + 0.006*император + 0.005*поехать + 0.005*цветочный + 0.004*выращивание + 0.004*медвежка + 0.004*нечистоты + 0.004*книга'),\n",
       " (3,\n",
       "  '0.033*растение + 0.021*2 + 0.016*22 + 0.012*земля + 0.011*вода + 0.007*корень + 0.006*конь + 0.006*река + 0.006*см + 0.006*размер'),\n",
       " (4,\n",
       "  '0.016*2222 + 0.013*год + 0.006*александр + 0.006*разбитый + 0.006*век + 0.005*песня + 0.004*новый + 0.004*гость + 0.004*г + 0.004*служить'),\n",
       " (5,\n",
       "  '0.008*2222 + 0.008*22 + 0.006*цветок + 0.006*культура + 0.004*саша + 0.004*2 + 0.004*также + 0.004*относиться + 0.004*молча + 0.004*форма'),\n",
       " (6,\n",
       "  '0.015*цветок + 0.011*цветочный + 0.011*стоять + 0.010*окно + 0.007*пол + 0.007*подоконник + 0.006*глиняный + 0.006*место + 0.006*разбивать + 0.006*ночной'),\n",
       " (7,\n",
       "  '0.015*ребенок + 0.012*мочь + 0.009*рука + 0.008*день + 0.007*сидеть + 0.007*год + 0.007*становиться + 0.007*говорить + 0.007*ходить + 0.006*время'),\n",
       " (8,\n",
       "  '0.015*голова + 0.013*ночной + 0.010*рука + 0.005*медведь + 0.004*глаз + 0.004*пойти + 0.004*фотография + 0.004*стол + 0.004*входить + 0.004*мимо'),\n",
       " (9,\n",
       "  '0.007*русский + 0.005*печь + 0.005*спина + 0.005*придумывать + 0.005*узкий + 0.004*вынимать + 0.004*молоко + 0.004*голова + 0.003*верить + 0.003*вываливать')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3': 'Ночной горшок', '1': 'Округлый глиняный сосуд для приготовления пищи (печной горшок)', '2': 'Расширяющийся кверху сосуд с отверстием в дне (цветочный горшок)'}\n",
      "(('телевизор, - ковер, , - музыкальный центр, - стол, - аквариум, - 3 шкафа, - цветы в', ' горшках', ', - мелкие аксессуары.'), '2')\n"
     ]
    }
   ],
   "source": [
    "import rl_wsd_labeled\n",
    "senses, contexts = rl_wsd_labeled.get_contexts(rl_wsd_labeled.contexts_filename('nouns', 'RuTenTen', 'горшок'))\n",
    "print(senses)\n",
    "print(contexts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymystem3\n",
    "import re\n",
    "MyStem = pymystem3.Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('телевизор, - ковер, , - музыкальный центр, - стол, - аквариум, - 3 шкафа, - цветы в', ' горшках', ', - мелкие аксессуары.')\n",
      "['телевизор', 'ковер', 'музыкальный', 'центр', 'стол', 'аквариум', '2', 'шкаф', 'цветок', 'мелкий', 'аксессуар']\n"
     ]
    }
   ],
   "source": [
    "word_re = re.compile('\\w+', re.U)\n",
    "def normalize(ctx):\n",
    "    left, _, right = ctx\n",
    "    text = ' '.join([left, right]).strip()\n",
    "    text = re.sub('\\d', '2', text)\n",
    "    return [w for w in MyStem.lemmatize(' '.join(word_re.findall(text)))\n",
    "            if w not in stopwords and w.strip()]\n",
    "print(contexts[0][0])\n",
    "print(normalize(contexts[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 3 3 3 7 7 6 3 3]\n",
      "[2 2 2 2 2 3 2 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "documents = [dictionary.doc2bow(normalize(ctx)) for ctx, _ in contexts]\n",
    "gamma, _ = lda.inference(documents)\n",
    "pred_topics = gamma.argmax(axis=1)\n",
    "true_labels = np.array([int(ans) for _, ans in contexts])\n",
    "print(pred_topics[:10])\n",
    "print(true_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI: 0.17530918009027194\n",
      "V score: 0.208410939616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import v_measure_score, adjusted_rand_score\n",
    "print('ARI:', adjusted_rand_score(true_labels, pred_topics))\n",
    "print('V score:', v_measure_score(true_labels, pred_topics))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
